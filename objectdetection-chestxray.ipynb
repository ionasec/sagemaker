{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectdetection-chestxray\n",
    "\n",
    "\n",
    "Object detection is the process of identifying and localizing objects in an image. A typical object detection solution takes an image as input and provides a bounding box on the image where an object of interest is found. It also identifies what type of object the box encapsulates. To create such a solution, we need to acquire and process a traning dataset, create and setup a training job for the alorithm so that it can learn about the dataset. Finally, we can then host the trained model in an endpoint, to which we can supply images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth process as per following blog:\n",
    "https://aws.amazon.com/blogs/aws/amazon-sagemaker-ground-truth-build-highly-accurate-datasets-and-reduce-labeling-costs-by-up-to-70/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data downloaded from here:\n",
    "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/data#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::773208840593:role/my_AmazonSageMakerFullAccess\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    " \n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813361260812.dkr.ecr.eu-central-1.amazonaws.com/object-detection:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://raz-sagemaker/models/object-detection-chest-xray/output\n",
      "s3://raz-sagemaker/annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest\n",
      "s3://raz-sagemaker/annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest\n"
     ]
    }
   ],
   "source": [
    "bucket = 'raz-sagemaker' \n",
    "prefix = 'models/object-detection-chest-xray'\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)\n",
    "\n",
    "bucket = 'raz-sagemaker'\n",
    "prefix = 'annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest'\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, prefix)\n",
    "s3_validation_data = s3_train_data\n",
    "print(s3_train_data)\n",
    "print(s3_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Object(bucket_name='raz-sagemaker', key='annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest')\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import tempfile\n",
    "\n",
    "s3 = boto3.resource('s3', sess.boto_region_name)\n",
    "bucket = s3.Bucket('raz-sagemaker')\n",
    "object = bucket.Object('annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest')\n",
    "tmp = tempfile.NamedTemporaryFile()\n",
    "print(object)\n",
    "\n",
    "with open(tmp.name, 'wb') as f:\n",
    "    object.download_fileobj(f)\n",
    "    \n",
    "with open(tmp.name) as f:\n",
    "    num_training_samples = sum(1 for line in f)\n",
    "    print (num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'Pipe',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object detection algorithm at its core is the Single-Shot Multi-Box detection algorithm (SSD). This algorithm uses a base_network, which is typically a VGG or a ResNet. The Amazon SageMaker object detection algorithm supports VGG-16 and ResNet-50 now. It also has a lot of options for hyperparameters that help configure the training job. The next step in our training, is to setup these hyperparameters and data channels for training the model. Consider the following example definition of hyperparameters. See the SageMaker Object Detection documentation for more details on the hyperparameters.\n",
    "\n",
    "One of the hyperparameters here for instance is the epochs. This defines how many passes of the dataset we iterate over and determines that training time of the algorithm. For the sake of demonstration let us run only 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=1,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=30,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=600,\n",
    "                             num_training_samples=num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', content_type='image/jpeg', s3_data_type='AugmentedManifestFile', attribute_names=['source-ref', 'raz-groundtruth-chest-xray-clone'])\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', content_type='image/jpeg', s3_data_type='AugmentedManifestFile', attribute_names=['source-ref', 'raz-groundtruth-chest-xray-clone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <sagemaker.inputs.s3_input object at 0x7f3a670def28>, 'validation': <sagemaker.inputs.s3_input object at 0x7f3a670def60>}\n",
      "2020-07-10 14:31:45 Starting - Starting the training job...\n",
      "2020-07-10 14:31:48 Starting - Launching requested ML instances.........\n",
      "2020-07-10 14:33:21 Starting - Preparing the instances for training.."
     ]
    }
   ],
   "source": [
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "print(data_channels)\n",
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
