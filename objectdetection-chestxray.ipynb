{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectdetection-chestxray\n",
    "\n",
    "\n",
    "Object detection is the process of identifying and localizing objects in an image. A typical object detection solution takes an image as input and provides a bounding box on the image where an object of interest is found. It also identifies what type of object the box encapsulates. To create such a solution, we need to acquire and process a traning dataset, create and setup a training job for the alorithm so that it can learn about the dataset. Finally, we can then host the trained model in an endpoint, to which we can supply images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth process as per following blog:\n",
    "https://aws.amazon.com/blogs/aws/amazon-sagemaker-ground-truth-build-highly-accurate-datasets-and-reduce-labeling-costs-by-up-to-70/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data downloaded from here:\n",
    "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/data#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::773208840593:role/my_AmazonSageMakerFullAccess\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    " \n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813361260812.dkr.ecr.eu-central-1.amazonaws.com/object-detection:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://raz-sagemaker/models/object-detection-chest-xray/output\n",
      "s3://raz-sagemaker/annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest\n",
      "s3://raz-sagemaker/annotation/chest_xray/validation/raz-groundtruth-chest-xray-clone-validation/manifests/output/output.manifest\n"
     ]
    }
   ],
   "source": [
    "bucket = 'raz-sagemaker' \n",
    "prefix = 'models/object-detection-chest-xray'\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)\n",
    "\n",
    "bucket = 'raz-sagemaker'\n",
    "prefix = 'annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest'\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, prefix)\n",
    "print(s3_train_data)\n",
    "\n",
    "bucket = 'raz-sagemaker'\n",
    "prefix = 'annotation/chest_xray/validation/raz-groundtruth-chest-xray-clone-validation/manifests/output/output.manifest'\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, prefix)\n",
    "print(s3_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Object(bucket_name='raz-sagemaker', key='annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest')\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import tempfile\n",
    "\n",
    "s3 = boto3.resource('s3', sess.boto_region_name)\n",
    "bucket = s3.Bucket('raz-sagemaker')\n",
    "object = bucket.Object('annotation/chest_xray/raz-groundtruth-chest-xray-clone/manifests/output/output.manifest')\n",
    "tmp = tempfile.NamedTemporaryFile()\n",
    "print(object)\n",
    "\n",
    "with open(tmp.name, 'wb') as f:\n",
    "    object.download_fileobj(f)\n",
    "    \n",
    "with open(tmp.name) as f:\n",
    "    num_training_samples = sum(1 for line in f)\n",
    "    print (num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'Pipe',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object detection algorithm at its core is the Single-Shot Multi-Box detection algorithm (SSD). This algorithm uses a base_network, which is typically a VGG or a ResNet. The Amazon SageMaker object detection algorithm supports VGG-16 and ResNet-50 now. It also has a lot of options for hyperparameters that help configure the training job. The next step in our training, is to setup these hyperparameters and data channels for training the model. Consider the following example definition of hyperparameters. See the SageMaker Object Detection documentation for more details on the hyperparameters.\n",
    "\n",
    "One of the hyperparameters here for instance is the epochs. This defines how many passes of the dataset we iterate over and determines that training time of the algorithm. For the sake of demonstration let us run only 30 epochs.\n",
    "\n",
    "Details here: \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-api-config.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=1,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=30,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=600,\n",
    "                             num_training_samples=num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', content_type='application/x-recordio', s3_data_type='AugmentedManifestFile', attribute_names=['source-ref', 'raz-groundtruth-chest-xray-clone'])\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', content_type='application/x-recordio', s3_data_type='AugmentedManifestFile', attribute_names=['source-ref', 'raz-groundtruth-chest-xray-clone-validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <sagemaker.inputs.s3_input object at 0x7f3a65953eb8>, 'validation': <sagemaker.inputs.s3_input object at 0x7f3a659531d0>}\n",
      "2020-07-10 15:28:20 Starting - Starting the training job...\n",
      "2020-07-10 15:28:22 Starting - Launching requested ML instances........."
     ]
    }
   ],
   "source": [
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "print(data_channels)\n",
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same insantance (or type of instance) that we used to train. Training is a prolonged and compute heavy job that require a different of compute and memory requirements that hosting typically do not. We can choose any type of instance we want to host the model. In our case we chose the ml.p3.2xlarge instance to train, but we choose to host the model on the less expensive cpu instance, ml.m4.xlarge. The endpoint deployment can be accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load a tet data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import boto3\n",
    "import tempfile\n",
    " \n",
    "s3 = boto3.resource('s3', region_name='eu-central-1')\n",
    "bucket = s3.Bucket('raz-sagemaker')\n",
    "object = bucket.Object('ultrasound-jpeg/09-41-06_1.jpg')\n",
    "tmp = tempfile.NamedTemporaryFile()\n",
    "print(object)\n",
    "\n",
    "with open(tmp.name, 'wb') as f:\n",
    "    object.download_fileobj(f)\n",
    "    img=mpimg.imread(tmp.name)\n",
    "    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
