{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 12, 'aggressive': 0, 'brown': 5, 'beast': 4, 'exasperated': 6, 'pedantic': 10, 'pontificator': 11, 'and': 1, 'anna': 2, 'has': 7, 'lots': 8, 'of': 9, 'apples': 3}\n",
      "(1, 13)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#\n",
    "# Bag-of-Words example\n",
    "#\n",
    "# Some text\n",
    "short_text = [\"The aggressive brown beast exasperated the pedantic pontificator. And Anna has lots of apples\"]\n",
    "# Create the vectorizer transformer\n",
    "vectorizer = CountVectorizer()\n",
    "# Tokenize and create the vocabulary\n",
    "vectorizer.fit(short_text)\n",
    "# Show the vectorized vocabulary\n",
    "print(vectorizer.vocabulary_)\n",
    "# Encode the text\n",
    "vector = vectorizer.transform(short_text)\n",
    "# Show the encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'all around', 'all around the', 'and', 'and dont', 'and dont know', 'and the', 'and the bit', 'around', 'around the', 'around the yard', 'be', 'be bit', 'be bit long', 'before', 'bit', 'bit his', 'bit his owner', 'bit long', 'bit long than', 'but', 'but it', 'but it should', 'dont', 'dont know', 'dont know this', 'get', 'get this', 'get this text', 'his', 'his owner', 'his owner and', 'it', 'it should', 'it should get', 'know', 'know this', 'know this makes', 'long', 'long than', 'long than before', 'makes', 'makes sense', 'makes sense or', 'not', 'not but', 'not but it', 'or', 'or not', 'or not but', 'owner', 'owner and', 'owner and dont', 'puppy', 'puppy ran', 'puppy ran all', 'ran', 'ran all', 'ran all around', 'sense', 'sense or', 'sense or not', 'should', 'should get', 'should get this', 'silly', 'silly puppy', 'silly puppy ran', 'text', 'text be', 'text be bit', 'than', 'than before', 'the', 'the bit', 'the bit his', 'the silly', 'the silly puppy', 'the yard', 'the yard and', 'this', 'this makes', 'this makes sense', 'this text', 'this text be', 'yard', 'yard and', 'yard and the']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# N-Gram example\n",
    "#\n",
    "# Create the vectorizer transformer\n",
    "ngram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "# Tokenize and create the vocabulary\n",
    "counts = ngram_vectorizer.fit_transform(['The silly puppy ran all around the yard and the bit his owner! and i dont know this makes sense or not but it should get this text be a bit long than before'])\n",
    "# Check the results\n",
    "print(ngram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use case - finding phrases in spam - n-gram - permutation of all the phrases\n",
    "\n",
    "#use case - finding combination\n",
    "\n",
    "#use case - finding subject of several pdfs - tf-idf / orthonogal sparse bigram - filter less importnat words / find common word combination\n",
    "\n",
    "\n",
    "#ortogonal Sprase Bigram\n",
    "#tf-idf - find important words by by frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
